{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb2cf2a",
   "metadata": {},
   "source": [
    "# Bayesian inference analysis notebook for strangeon matter EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc633d3",
   "metadata": {},
   "source": [
    "This is an example notebook about how to use our tools to analysis a observation constraint on strangeon star equation of state.\n",
    "\n",
    "Here in this notebook, we are using a strangeon matter EOS.\n",
    "\n",
    "The following is the package that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f20856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import InferenceWorkflow.BayesianSampler as sampler\n",
    "import InferenceWorkflow.Likelihood as likelihood\n",
    "import InferenceWorkflow.prior as prior\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from TOVsolver.constant import oneoverfm_MeV, m_rho, m_w,G,c\n",
    "import TOVsolver.main as main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7655c1",
   "metadata": {},
   "source": [
    "The constans that we will used in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fdb5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3e10  # Speed of light in cm/s\n",
    "G = 6.67428e-8  # Gravitational constant in cm^3/g/s^2 or dyne cm^2/g^2\n",
    "Msun = 1.989e33  # Solar mass in grams\n",
    "\n",
    "dyncm2_to_MeVfm3 = 1./(1.6022e33)  # Conversion factor from dyn/cm^2 to MeV/fm^3\n",
    "gcm3_to_MeVfm3 = 1./(1.7827e12)  # Conversion factor from g/cm^3 to MeV/fm^3\n",
    "oneoverfm_MeV = 197.33  # Conversion factor for fm to MeV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b494a39",
   "metadata": {},
   "source": [
    "The following is the strangeon matter EOS function.\n",
    "\n",
    "We note that because the parameter Nq is an integer in the strangeon matter EOS.\n",
    "\n",
    "In the following, we use a possible value of this parameter, Nq=18, as an example to carry out the Bayesian analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d879d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nq=18\n",
    "\n",
    "def Strangeon_compute_EOS(n, theta): \n",
    "    \"\"\"\n",
    "    Compute the energy density and pressure based on the given parameters.\n",
    "\n",
    "    Args:\n",
    "        n (array): An array of n values. Input values of baryon number densities.\n",
    "        theta (array): An array representing the parameters [epsilon, Nq, ns].\n",
    "        epsilon: the depth of the potential well; MeV;\n",
    "        Nq: the number of quarks in a strangeon; \n",
    "        ns: the number density of baryons at the surface of the star; fm^-3\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Arrays of energy densities in units of gcm3 and pressures in units of dyncm2.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    epsilon, ns = theta\n",
    "    \n",
    "    A12 = 6.2\n",
    "    A6 = 8.4 \n",
    "    mq = 300 \n",
    "    \"\"\"\n",
    "    mq: the mass of the quark in this EOS.\n",
    "    A12 and A6 are fixed throughout the calculation.\n",
    "    \"\"\"\n",
    "   \n",
    "    sigma = np.sqrt(A6 / (2 * A12)) * (Nq / (3 * ns)) \n",
    "   \n",
    "    energy_density = 2 * epsilon * (A12 * sigma**4 * n**5 - A6 * sigma**2 * n**3) + n * Nq * mq\n",
    "    pressure = 4 * epsilon * (2 * A12 * sigma**4 * n**5 - A6 * sigma**2 * n**3)\n",
    "    \n",
    "    return energy_density*G/c**2/gcm3_to_MeVfm3, pressure*G/c**4/dyncm2_to_MeVfm3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa0f72",
   "metadata": {},
   "source": [
    "# Set up prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38136542",
   "metadata": {},
   "source": [
    "Next step, we need to set up the prior, first use parameters array to specify the variable name, this process should consistent with what you need to call them.\n",
    "\n",
    "Define a prior transform function to define prior. Cube are set of random number from 0 to 1. This prior setting is standard set-up of UltraNest package, since we are using UltraNest to do nest-sampling.\n",
    "\n",
    " We provided two options call from prior:\"normal_Prior\" and \"flat_prior\".\n",
    " \n",
    "Then the Parameters prior should all set.\n",
    "\n",
    "We note that since we are doing Equation of state Inference from mass-radius data of neutron star measurement. The center density of the star should be also sampled. Otherwise will be a partially-defined prior, did not span all parameters space, and proved to be different with full-scope inference.\n",
    "\n",
    "This request as randomly generate a density from a EoS range, however, this process is not that trivial, since we need to determine the upper limit of the central density of compact star --- different equation of state will predict different upper bound, so here we need to use the prior-setting EoS parameters computing the EOS by\n",
    "\n",
    "strangeon.compute_EOS\n",
    "Compute out EOS, put into\n",
    "\n",
    "main.OutputMR\n",
    "\n",
    "find out Mass Radius of this equation of state, then find out the last stable point of this equation of state.(first mass points that give the direvative to be negative)\n",
    "\n",
    "and find out that index by len() function, then reset this max_d to be upper limit of this density range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b87dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [ 'epsilon', 'ns', 'd1']\n",
    "# for two or more MR measurements, define \n",
    "# parameters = ['epsilon', 'ns', 'd1', 'd2'] \n",
    "\n",
    "def prior_transform(cube):\n",
    "    params = cube.copy()\n",
    "    params[0] = prior.flat_prior(10, 170,cube[0])   #epsilon=10-170MeV\n",
    "    params[1] = prior.flat_prior(0.17,0.36,cube[1]) #ns=0.17-0.36fm^-3    \n",
    "    \n",
    "    epsilon = params[0]\n",
    "    ns = params[1]\n",
    "\n",
    "    theta = np.array([epsilon, ns])\n",
    "    \n",
    "    # Define the range for n based on the provided formulas\n",
    "    n_min = 3 * theta[1] / Nq      #n_min=3*ns/Nq\n",
    "    n_max = 0.16 * 8 * 3 / Nq      #n_max=0.16*8*3/Nq\n",
    "    n_values = np.linspace(n_min, n_max, 100)  # 100 points between n_min and n_max\n",
    "    \n",
    "    energy_density, pressure = Strangeon_compute_EOS(n_values, theta) \n",
    "\n",
    "    eps_total=energy_density\n",
    "    \n",
    "    pres_total=pressure\n",
    "    \n",
    "    RFSU2R = [] \n",
    "    MFSU2R = []\n",
    "    density = np.logspace(14.3, 15.6, 50) \n",
    "    if all(x<y for x,y in zip(eps_total[:], eps_total[1:])) and all(x<y for x, y in zip(pres_total[:], pres_total[1:])):\n",
    "        MR = main.OutputMR('',energy_density,pressure).T  \n",
    "    else:\n",
    "        MR = []\n",
    "    if len(MR) == False: \n",
    "        params[2] = 0\n",
    "        #params[3] = 0\n",
    "        #this line for showing how to add one more observation\n",
    "    else:\n",
    "   \n",
    "        for i in range(len(MR[1])):\n",
    "            RFSU2R.append(MR[0][i])\n",
    "            MFSU2R.append(MR[1][i])   \n",
    "            if i > 20 and MR[1][i] - MR[1][i-1]< 0:    \n",
    "                break\n",
    "    if len(MFSU2R)==False:\n",
    "        params[2] = 0\n",
    "        #params[3] = 0\n",
    "        #this line for showing how to add one more observation\n",
    "    else:\n",
    "        max_index = len(MFSU2R)\n",
    "        max_d = np.log10(density[max_index-1])\n",
    "        params[2] = 14.3 + (max_d - 14.3) * cube[2]\n",
    "        #params[3] = 14.3 + (max_d - 14.3) * cube[3]\n",
    "        #this line for showing how to add one more observation\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e4822",
   "metadata": {},
   "source": [
    "In the upper part, we define a flat (uniform) prior for the parameters in the strangeon matter equation of state, due to the lack of constraints from terrestrial experiments.\n",
    "\n",
    "Note that the above code is an example of Bayesian analysis for a given mass and radius observation measurement.\n",
    "For example, if you use the NICER data for the measurements of J0030, then you should define another parameter, except the strangeon EOS parameters, e.g. \"d1\" for the centre density of this measurement, in the meantime add \"params[2]\" to this code.\n",
    "\n",
    "If you further consider the adjoint analysis with J0030+J0740, then you should define the other two parameters, e.g. \"d1\" and \"d2\" for the centre density of these two measurements, in the meantime add \"params[3]\" to the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab6d43",
   "metadata": {},
   "source": [
    "# Set up likehood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd12ff",
   "metadata": {},
   "source": [
    "We need to set up a likelihood, Using standard definition way of UltraNest, that is below.\n",
    "\n",
    "Here the likelihood is generated from a simulated mass radius measurement, which is  ð‘€=1.4ð‘€âŠ™\n",
    "  and  ð‘…=13\n",
    "  km, With a 5% Mass radius measurement uncertainty, \n",
    "  \n",
    " so here\n",
    " \n",
    "      likelihood.MRlikihood_Gaussian\n",
    "      \n",
    "function will be use for our likelihood, please check [likelihood.MRlikihood_Gaussian](https://github.com/ChunHuangPhy/CompactOject/blob/main/InferenceWorkflow/Likelihood.py) to see the original code, and more choice of likelihood. eg:\n",
    "\n",
    "1.If we have some real mass-radius measurements, say PSR J0030 or PSR J0740, come from NICER, a KDE kernel could be trained to feed into\n",
    "\n",
    "likelihood.MRlikihood_kernel(eps_total,pres_total,x,d1)\n",
    "\n",
    "set the KDE kernel as a input for this function\n",
    "\n",
    "2.If we gain measurement from radio-timing, say only measure the neutron star mass, then\n",
    "\n",
    "likelihood.Masslikihood_Gaussian(eps_total,pres_total,x,d1)\n",
    "\n",
    "Which will give the likelihood from single mass measurement, x is the parameters of that measurement, you should specify where this measurement mass is located and what is the sigma width of this mass measurement.\n",
    "\n",
    "3.If we have nuclear measurements, and want to constrain this RMF model by nuclear properties like K(The Incompressibility of nuclear matter),J ( the symmetry energy at saturation density) and L( the slope of symmetry energy at saturation density). You can choose:\n",
    "\n",
    "likelihood.Kliklihood(theta,K_low,K_up)\n",
    "likelihood.Jliklihood(theta,K_low,K_up)\n",
    "likelihood.Lliklihood(theta,K_low,K_up)\n",
    "\n",
    "We are defaulting a hard-cut flat constrain, so if you don't like this default hard cut, also could define the likelihood by youself with similiar style.\n",
    "\n",
    "4.If we have a Tidal measurements from Gravitational wave detector, we can use it to do constraint:\n",
    "\n",
    "likelihood.TidalLikihood_kernel(eps_total,pres_total,x,d1)\n",
    "\n",
    "Where x is sampled distribution from real measurements, the standard is\n",
    "\n",
    "kernel, chrip = x,\n",
    "\n",
    "where the kernel is a whole set sampling from GW event, that is [chrip mass, M2/M1, tidal of M1, tidal of M2] four quantities. Chrip is the single smapling that comes only the chrip mass sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d3a8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def MRlikihood_Gaussian(eps_total,pres_total,x,d1):\n",
    "    \"\"\"Computing likelihood from a simulation gaussian distribution of MR measurement\n",
    "    \n",
    "    Args:\n",
    "        eps_total (array): the energy density of full EoS in MeV/fm3, times a G/c**2 factor\n",
    "        pres_total (array): the pressure from full EoS model in MeV/fm3, times a G/c**4 factor\n",
    "        x (float array): [Mvalue, Rvalue, Mwidth, Rwidth], Mvalue is the Mass center value of this \n",
    "        simulated measurement, Rvalue is the Radius center of it, Mwidth is the 1-sigma width of\n",
    "        this Mass measurement, Rwidth is the 1-sigma width of this radius measurement.\n",
    "        d1 (float): the sampled density of this measurement\n",
    "\n",
    "    Returns:\n",
    "        likelihood (float): likelihood feed back for this given paramter set-up.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    Mvalue, Rvalue, Mwidth,Rwidth = x\n",
    "    \n",
    "    sigma_x = Rwidth\n",
    "    sigma_y = Mwidth\n",
    "    \n",
    "    if d1 ==0 :\n",
    "        likelihood = -1e101\n",
    "    else:\n",
    "        d1 = 10**(d1)\n",
    "        if   all(x<y for x,y in zip(eps_total[:], eps_total[1:])) and all(x<y for x, y in zip(pres_total[:], pres_total[1:])):\n",
    "            MR = main.OutputMRpoint(d1,eps_total,pres_total).T\n",
    "        else:\n",
    "            MR = []\n",
    "        if len(MR) == False:\n",
    "            likelihood = -1e101\n",
    "        else:\n",
    "            fx = 1/(sigma_x*sigma_y*(np.sqrt(2*np.pi))**2)*np.exp(-np.power(MR[0][0]-Rvalue, 2.)/(2*np.power(sigma_x,2.))-np.power(MR[1][0]-Mvalue, 2.)/(2*np.power(sigma_y,2.)))\n",
    "            likelihood = np.log(fx)\n",
    "    if likelihood <= -1e101:\n",
    "        return -1e101\n",
    "    else:\n",
    "        return likelihood\n",
    "    \n",
    "def likelihood_transform(theta):\n",
    "    # This is a demonstration code for only introduce one constraint from one mass-radius observation.\n",
    "    # Could be very easy to implement more constraint from nuclear quantity, since that do not need to\n",
    "    # sample more central density of real neutron star. If user want to expand to two mass radius measurement \n",
    "    # the code could be:\n",
    "      \n",
    "    epsilon, ns, d1 = theta \n",
    "    # comment this line if you need two measuremnts.\n",
    "    #epsilon, ns, d1, d2 = theta\n",
    "    \n",
    "    ####################################################################################################################\n",
    "    ############ This is the block to compute out all the EoS you need based on your parameters#########################\n",
    "    theta = np.array([epsilon, ns]) \n",
    "    n_min = 3 * theta[1] / Nq      #n_min=3*ns/Nq\n",
    "    n_max = 0.16 * 8 * 3 / Nq      #n_max=0.16*8*3/Nq\n",
    "    n_values = np.linspace(n_min, n_max, 100)  # 100 points between n_min and n_max\n",
    "    energy_density_total, pressure_total = Strangeon_compute_EOS(n_values, theta)\n",
    "\n",
    "    ####################################################################################################################\n",
    "    \n",
    "    probMRgaussian = MRlikihood_Gaussian(energy_density_total,pressure_total,(1.4,13,0.07,0.65),d1)\n",
    "    \n",
    "    prob = probMRgaussian\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d26ce7",
   "metadata": {},
   "source": [
    "In the following, we will show how to modify the likehood_transform function when considering more observations.\n",
    "\n",
    "def likelihood_transform(theta):\n",
    "\n",
    "    Nq, epsilon, ns, d1 = theta \n",
    "    theta = np.array([epsilon, ns]) \n",
    "    n_min = 3 * theta[1] / Nq      #n_min=3*ns/Nq\n",
    "    n_max = 0.16 * 8 * 3 / Nq      #n_max=0.16*8*3/Nq\n",
    "    n_values = np.linspace(n_min, n_max, 100)  # 100 points between n_min and n_max\n",
    "    energy_density_total, pressure_total = Strangeon_compute_EOS(n_values, theta)\n",
    "    \n",
    "    #1. This line is to compute MR likelihood from a Simulated MR measurement:\n",
    "    \n",
    "    probMRgaussian = MRlikihood_Gaussian(energy_density_total,pressure_total,(1.4,13,0.07,0.65),d1)\n",
    "    \n",
    "    #probMRgaussian = likelihood.MRlikihood_Gaussian(energy_density_total,pressure_total,(2.08,13,0.08,0.65),d2)\n",
    "    \n",
    "    #2. This is  a block that constrain from given real MR measurement, say J0030:\n",
    "    \n",
    "    #J0030 = numpy.loadtxt('data/PST_equal_sampled_MR.txt', delimiter=' ')\n",
    "    #J30R_list, J30M_list = zip(*J0030)\n",
    "    #J30R_list = numpy.array(J30R_list).T    \n",
    "    #J30M_list = numpy.array(J30M_list).T\n",
    "    #Rmin = J30R_list.min()\n",
    "    #Rmax = J30R_list.max()\n",
    "    #Mmin = J30M_list.min()\n",
    "    #Mmax = J30M_list.max()\n",
    "    #X3, Y3 = numpy.mgrid[Rmin:Rmax:500j, Mmin:Mmax:100j]\n",
    "    #positions = numpy.vstack([X3.ravel(), Y3.ravel()])\n",
    "    #values = numpy.vstack([J30R_list, J30M_list])\n",
    "    #kernel3 = stats.gaussian_kde(values)\n",
    "    #probMRJ0030 = likelihood.MRlikelihhood_kernel(eps_total,pres_total,kernel3,d1)\n",
    "    \n",
    "    #3. This is to compute the constraint from experiment of nuclearmatter\n",
    "    # 250<K<400, 25<J<38, 30<L<86:\n",
    "    # hint: since this K,J,L sampling don't need to sample central density so this \n",
    "    # theta should be redifined.\n",
    "    #probK = likelihood.Kliklihood(theta,250,400)\n",
    "    #probJ = likelihood.Jliklihood(theta,250,400)\n",
    "    #probL = likelihood.Lliklihood(theta,250,400)\n",
    "    \n",
    "    #4. This is block to cosntrain from a GW event, say GW170817, here the file of this\n",
    "    # event is origanized by [chrip mass, M2/M1, tidal of M1, tidal of M2, sampling weight]:\n",
    "    #GW170817 = np.load('GW170817_McQL1L2weights.npy')\n",
    "    #chrip170817 = stats.gaussian_kde(GW170817[:,0],weights = GW170817[:,4])\n",
    "    #kernelGW = stats.gaussian_kde(GW170817.T[0:4],weights = GW170817[:,4])\n",
    "    #probGW = likelihood.TidalLikihood_kernel(eps_total,pres_total,(kernelGW,chrip170817),d1)\n",
    "    \n",
    "    \n",
    "    prob = probMRgaussian\n",
    "    \n",
    "    #prob =  probGW#+ probMRJ0030 + probK + probJ + probL + probGW\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3802c4",
   "metadata": {},
   "source": [
    "# Set up sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bce7fb",
   "metadata": {},
   "source": [
    "Here next, we define sampler, there is two different sampler we provided for. \n",
    "\n",
    "Considering where you need resume file:\n",
    "\n",
    "sampler.UltranestSampler   and  sampler.UltranestSamplerResume\n",
    "\n",
    "Here since it is our first run, so we only use first one. Some of the sampler parameters is requested, first is step number, our choice for UltraNest sampler is slicesampler, which could easily be sliced up your total computation load, and parallelize, speed up sampling. So step as suggested by documentation of UltraNest, we use 2*len(parameters).\n",
    "\n",
    "live_point we set 2000, it will influence the sampling precision, We suggest for 7 dimension space, maybe 5000 is a better choice, however, since my computer only have limited resources, we set 2000.\n",
    "\n",
    "max_calls set 10000, it is how many iteration after it will stop, we suggest to set this number significantly higher, otherwise maybe will broken before the inference converging to a definite value. That result will be un-phyiscal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05849a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory for new run output\\run6\n",
      "[ultranest] Sampling 400 live points from prior ...\n",
      "[ultranest] Widening roots to 634 live points (have 400 already) ...\n",
      "[ultranest] Sampling 234 live points from prior ...\n",
      "[ultranest] Widening roots to 996 live points (have 634 already) ...\n",
      "[ultranest] Sampling 362 live points from prior ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f67582fe73547da80cf6c24a608e58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), GridspecLayout(children=(HTML(value=\"<div style='background-color:#6E6BF4;'>&nbâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z=-29.8(0.07%) | Like=-24.83..-14.77 [-25.9556..-23.3236] | it/evals=1800/16166 eff=7.9367% N=400   \r"
     ]
    }
   ],
   "source": [
    "step = 2 * len(parameters)\n",
    "live_point = 400\n",
    "\n",
    "max_calls = 60000\n",
    "samples = sampler.UltranestSampler(parameters,likelihood_transform,prior_transform,step,live_point,max_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240dec67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
